
                            < M A T L A B (R) >
                  Copyright 1984-2015 The MathWorks, Inc.
                   R2015a (8.5.0.197613) 64-bit (glnxa64)
                             February 12, 2015

 
To get started, type one of these: helpwin, helpdesk, or demo.
For product information, visit www.mathworks.com.
 

	Academic License

p = 3
n = 10
rf start
Trial 1
Starting parallel pool (parpool) using the 'local' profile ... [Warning: The Cluster reported an error while destroying a job. The error was:
Unable to read file
'/home-4/ttomita2@jhu.edu/.matlab/local_cluster_jobs/R2015a/Job36.in.mat'. No
such file or directory..] 
[> In parallel.internal.cluster.CJSJobMethods.destroyOneJob (line 78)
  In parallel.job.CJSCommunicatingJob/destroyOneJob (line 94)
  In parallel.Job/delete (line 1046)
  In parallel.Cluster/hDeleteOneJob (line 845)
  In parallel.internal.pool.InteractiveClient>iDeleteJobs (line 848)
  In parallel.internal.pool.InteractiveClient/pRemoveOldJobs (line 471)
  In parallel.internal.pool.InteractiveClient/start (line 311)
  In parallel.Pool>iStartClient (line 547)
  In parallel.Pool.hBuildPool (line 439)
  In parallel.internal.pool.doParpool (line 15)
  In parpool (line 89)
  In run_Sparse_parity_raw_vary_n_rf (line 140)] 
[Warning: The cluster failed to cancel the job execution. The error was: Unable
to read file
'/home-4/ttomita2@jhu.edu/.matlab/local_cluster_jobs/R2015a/Job38.in.mat'. No
such file or directory.] 
[> In parallel.internal.cluster.CJSJobMethods.cancelOneJob (line 53)
  In parallel.job.CJSCommunicatingJob/cancelOneJob (line 99)
  In %2465322436>@(j1)cancelOneJob(j1,cancelException)
  In parallel.Job/cancel (line 1109)
  In parallel.Cluster/hDeleteOneJob (line 830)
  In parallel.internal.pool.InteractiveClient>iDeleteJobs (line 848)
  In parallel.internal.pool.InteractiveClient/pRemoveOldJobs (line 471)
  In parallel.internal.pool.InteractiveClient/start (line 311)
  In parallel.Pool>iStartClient (line 547)
  In parallel.Pool.hBuildPool (line 439)
  In parallel.internal.pool.doParpool (line 15)
  In parpool (line 89)
  In run_Sparse_parity_raw_vary_n_rf (line 140)] 
[Warning: The cluster reported an error while deleting an unavailable job.  This
job may already have been deleted.] 
[> In parallel.internal.cluster.CJSJobMethods.destroyOneJob (line 76)
  In parallel.job.CJSCommunicatingJob/destroyOneJob (line 94)
  In parallel.Job/delete (line 1046)
  In parallel.Cluster/hDeleteOneJob (line 845)
  In parallel.internal.pool.InteractiveClient>iDeleteJobs (line 848)
  In parallel.internal.pool.InteractiveClient/pRemoveOldJobs (line 471)
  In parallel.internal.pool.InteractiveClient/start (line 311)
  In parallel.Pool>iStartClient (line 547)
  In parallel.Pool.hBuildPool (line 439)
  In parallel.internal.pool.doParpool (line 15)
  In parpool (line 89)
  In run_Sparse_parity_raw_vary_n_rf (line 140)] 
connected to 12 workers.
[Warning: File:
/scratch/groups/jvogels3/tyler/RandomerForest/Code/Classifiers/@rpclassificationforest/rpclassificationforest.m
Line: 207 Column: 47
The temporary variable ibidx will be cleared at the beginning of each iteration
of the parfor loop.
Any value assigned to it before the loop will be lost.  If ibidx is used before
it is assigned in the parfor loop, a runtime error will occur.
See Parallel for Loops in MATLAB, "Temporary Variables".] 
[> In RerF_train (line 222)
  In run_Sparse_parity_raw_vary_n_rf (line 144)] 
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
n = 100
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
n = 1000
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
p = 10
n = 100
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
n = 1000
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
n = 10000
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
p = 20
n = 1000
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
n = 5000
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
n = 10000
rf start
Trial 1
Training complete
Trial 2
Training complete
Trial 3
Training complete
Trial 4
Training complete
Trial 5
Training complete
Trial 6
Training complete
Trial 7
Training complete
Trial 8
Training complete
Trial 9
Training complete
Trial 10
Training complete
rf complete
